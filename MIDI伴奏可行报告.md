------

# MIDI伴奏可行报告

## 项目概述

希望面向专业演奏者与音乐爱好者，核心功能是

**1. 尽量让midi的实时预览变好听**

**2. 通过实时识别用户的独奏节奏和速度，自动生成或控制虚拟交响乐团的伴奏**

目的是能让钢琴、小提琴、长笛、甚至架子鼓等独奏者，在没有乐团的情况下，也能得到自然、灵动的伴奏体验。

------

## 可能的市场痛点与机会

1. 传统的音频伴奏（Backing Tracks）是静态的，无法跟随演奏者的艺术处理（如自由速度 Rubato、延长音 Fermata 或突发的节奏变化）。而聘请真人钢琴伴奏或交响乐团不仅成本高昂，且难以随时获取。*
2. **可能存在的算法加持**
    开发实时音频分析和AI音乐生成技术，或有机会填补“智能伴奏”这一细分市场空白。

 **市场定位：**希望练习协奏曲的爱好者以及其他难以独自演奏的非交响乐器演奏者

------

## 最关心的问题

1. **版权**：不选择各大乐团的录音 一般单纯midi文件就无版权纠纷，谱子要么自制midi，要么扒imslp等开源库即可。
2. **midi引擎**：考察了两个开源的：FluidSynth和Flutter，同时要考虑高品质midi库，比如买SoundFont 的商业授权。
3. **技术**：块状加速器太过复杂，这个方案没什么现实意义。已删除。

------

## 技术架构和可行性分析（gemini）

技术上可以分解为三个核心模块：**音频感知与特征提取**、**实时乐谱跟随算法**、以及**高保真音频合成引擎**

### 2.1 核心技术架构：移动端优先的混合开发模式

考虑到团队规模限制，必须避免为iOS和Android维护两套原生代码。同时，实时音频处理对性能要求极高，不能完全依赖解释型语言（如Dart或JavaScript）。因此，推荐采用 **Flutter (UI) + C++ (核心引擎)** 的架构 1。

#### 2.1.1 移动端架构（核心路径）

- **用户界面层 (Flutter):** 负责乐谱渲染、用户交互、设置管理。Flutter 的 Impeller 渲染引擎能够保证乐谱滚动的流畅性（60fps+），这对视奏体验至关重要。
- **逻辑控制层 (Dart):** 处理业务逻辑，通过 `dart:ffi` (Foreign Function Interface) 与底层 C++ 引擎进行同步通信。FFI 的同步调用特性对于低延迟音频应用是决定性的，因为它避免了异步消息传递带来的抖动 2。
- **音频引擎层 (C++):** 这是系统的核心，包含两个子模块：
  - **监听模块：** 集成 **Oboe** 音频库 3。Oboe 是 Google 开发的 C++ 库，能够自动选择 Android 系统上延迟最低的音频 API（AAudio 或 OpenSL ES），并统一 iOS 的 CoreAudio 接口。这是解决 Android 设备音频延迟碎片化问题的关键。
  - **算法模块：** 运行乐谱跟随算法（OLTW/HMM）和音频合成器（FluidSynth）。

#### 2.1.2 Web 与桌面端的可能性

- **桌面端 (Windows/macOS):** Flutter 本身支持桌面端编译。底层的 C++ 引擎可以直接复用，只需调整 Oboe 为各平台的原生音频 API（如 Windows 的 WASAPI 或 macOS 的 CoreAudio）。这对于 5 人团队来说，几乎是零额外成本的扩展。
- **Web 端 (WASM):** 技术上可行，但挑战巨大。C++ 引擎可以通过 **Emscripten** 编译为 **WebAssembly (WASM)**，在浏览器中运行。然而，Web Audio API 的输入延迟通常高于原生应用，且 SoundFont（音色库）文件较大（几百 MB），在 Web 端加载会严重影响用户体验。<u>批注：无需考虑</u>
  - <u>***结论：* 建议初期仅将其作为营销展示（Demo），而非核心产品形态。**</u>

### 2.2 关键算法技术路线：乐谱跟随 (Score Following)

任务是将实时采集的音频流与预设的 MIDI 乐谱进行时间轴对齐。

#### 2.2.1 算法选型：在线时间规整 (OLTW)

传统的离线对齐（Offline Alignment）如 DTW（动态时间规整）需要完整的音频文件，不适用于实时伴奏。对于实时应用，必须使用 **在线时间规整 (Online Time Warping, OLTW)** 或 **隐马尔可夫模型 (HMM)** 。

| **算法**                  | **原理**                                             | **优点**                                        | **缺点**                                               | **适用性**           |
| ------------------------- | ---------------------------------------------------- | ----------------------------------------------- | ------------------------------------------------------ | -------------------- |
| **OLTW (Dixon/Arzt)**     | 基于动态规划，实时计算最佳路径，维护一个“搜索窗口”。 | 计算效率高，对局部速度变化鲁棒，实现资料丰富 。 | 若用户跳跃演奏或严重错音，容易丢失跟踪（Drift）。      | **极高（推荐首选）** |
| **HMM / Particle Filter** | 概率模型，预测当前处于乐谱中某个位置（状态）的概率。 | 能更好地处理错音、跳段和休止符；抗噪性强。      | 计算复杂度高，参数调试极其困难（如状态转移概率矩阵）。 | 中（作为进阶优化）   |
| **纯 AI (深度学习)**      | 端到端神经网络直接预测位置。                         | 理论上准确率上限高。                            | 延迟通常较大，且需要海量标注数据训练，不适合小团队。   | 低                   |



**推荐方案：** 基于 **Matchmaker** 开源库的逻辑移植。Matchmaker 4 提供了 OLTW 算法的标准 Python 实现。团队应深入研读其源码，将其核心逻辑移植到 C++ 中，配合 **Essentia** 库进行特征提取。

#### 2.2.2 特征提取 (Feature Extraction)

算法不能直接处理波形，需要提取特征。对于协奏曲（通常是复调音乐），单纯的音高检测（Pitch Detection）不够稳健。

- **Chroma Features (色度图):** 将频谱映射到 12 个音级（C, C#, D...）。它对音色变化不敏感，能很好地匹配独奏乐器与钢琴谱/总谱的 MIDI 缩谱 。
- **Spectral Flux (频谱通量):** 用于检测音符的起始点（Onset）。只有准确检测到用户何时“开始”演奏一个音，伴奏才能同步切入。

### 2.3 技术可行性总结

对于小团队，最大的风险在于**算法的鲁棒性**。建议分阶段实施：

1. **MVP 阶段：** 实现基于 OLTW 的跟随，仅支持速度跟随，不支持大幅度跳跃。
2. **优化阶段：** 引入卡尔曼滤波（Kalman Filter）对速度预测进行平滑处理，防止伴奏忽快忽慢 5。

------

## 3. 竞品与市场现状分析

当前市场呈现两极分化：一端是拥有海量曲库但交互性差的“播放器类”应用，另一端是技术先进但价格昂贵且曲库有限的“AI 伴奏类”应用。

### 3.1 主要竞品分析

#### 3.1.1 Tomplay 

- **定位：** 交互式乐谱市场领导者。
- **核心优势：** 拥有大量与其乐谱同步的**真人录音**（Audio Recordings）。音质极佳，因为是真实录音。
- **致命弱点：** **缺乏真正的聆听功能**。用户必须跟随 App 的速度，或者手动调节速度。当调节速度时，音频会因时间伸缩（Time-stretching）产生伪影（Artifacts），且无法做自由速度（Rubato）。
- **对标策略：** 您的产品通过 MIDI 实现“无限精度的速度跟随”和“无损变速”，这是 Tomplay 无法做到的。

#### 3.1.2 Metronaut 

- **定位：** 基于 AI 的实时伴奏应用（主要在 iOS）。
- **核心技术：** 使用 Antescofo 技术（源自 IRCAM 研究所），支持实时跟随。
- **弱点：** 订阅费用昂贵；主要依赖音频时间伸缩技术（Elastic Audio），在用户演奏速度极慢或极快时，伴奏声音会变得怪异。且 Android 版本体验常年落后于 iOS。
- **对标策略：** 利用 MIDI 引擎的特性，即使在极慢速练习下也能保持乐器音色的自然（不会出现音频拉伸的颗粒感）。

#### 3.1.3 SmartMusic (MakeMusic Cloud) 

- **定位：** 美国 K-12 音乐教育标准工具。
- **核心优势：** 强大的评估系统（红绿音符打分）。
- **弱点：** 面向机构，UI/UX 沉重，价格高昂，主要侧重于“考核”而非“演奏乐趣”。
- **对标策略：** 避开“教育/打分”红海，主打“演奏/享受”，针对成年业余爱好者或高阶琴童的练习需求。

#### 3.1.4 MuseScore 

- **定位：** 最大的乐谱社区。
- **现状：** 拥有 Muse Sounds（高质量合成器），但移动端 App 主要用于回放，尚无实时跟随功能。
- **威胁：** 如果 MuseScore 决定下场做实时跟随，将是最大的巨头威胁。

### 3.2 市场蓝海与切入点

目前市场上缺乏一款**“低延迟、高音质、基于 MIDI 但听感接近真实乐团、且价格亲民”**的 Android/iOS 双平台应用。

- **痛点：** 现有的 MIDI 播放器声音像“玩具”（General MIDI 8MB 音色库），而真实录音伴奏（Tomplay）又太死板。
- **机会：** 利用现代手机 4GB+ 的内存，加载 **200MB-500MB 级别的高质量 SoundFont**，配合实时跟随算法，提供一种介于真实录音与传统 MIDI 之间的新体验。

------

## 4. 针对少于5人团队（资金10w）的技术选型建议

**资金警示：** 10 万元人民币（约 1.4 万美元）对于软件研发来说极其微薄。这笔钱不足以支付工资，甚至不足以购买高端服务器或大量商业授权。因此，技术选型必须遵循**“开源优先、零授权费优先、性能优先”**的原则。团队成员必须是技术合伙人（以股权为回报），而非雇员。

### 4.1 核心技术栈推荐

| **模块**         | **推荐技术**             | **理由**                                                     | **成本**          |
| ---------------- | ------------------------ | ------------------------------------------------------------ | ----------------- |
| **移动端框架**   | **Flutter**              | 跨平台效率之王，Impeller 引擎渲染乐谱流畅，FFI 调用 C++ 性能损耗极低 1。 | 免费 (MIT)        |
| **音频 I/O**     | **Oboe** (Google)        | 解决 Android 延迟问题的唯一正解。自动适配 AAudio/OpenSL ES 3。 | 免费 (Apache 2.0) |
| **音频合成引擎** | **FluidSynth**           | 成熟的 SoundFont 2 合成器，C 语言编写，性能极高，易于集成到 C++ 15。 | 免费 (LGPL)       |
| **特征提取**     | **Essentia** (C++)       | 提供了标准的 Chroma、Onset、Spectral Flux 算法，且针对实时处理进行了优化 16。 | 免费 (AGPL v3*)   |
| **乐谱跟随逻辑** | **移植 Matchmaker**      | 将 Python 库 Matchmaker 中的 OLTW 逻辑重写为 C++ 4。         | 研发时间成本      |
| **乐谱渲染**     | **Lomse** 或 **VexFlow** | Lomse 是 C++ 库，适合直接集成；VexFlow 是 JS 库，若用 Flutter Webview 渲染也可以。推荐 Lomse 以保持原生性能 18。 | 免费              |



*注：Essentia 的 AGPL 协议要求开源。如果你们计划闭源商业化，可能需要联系 MTG 购买商业授权，或者改用 **Aubio** (GPL) 并封装隔离，或使用宽松协议的 **KissFFT** 自行实现 Chroma 提取。考虑到预算，建议初期使用宽松协议的库如 **Miniaudio** 配合自行实现的 DSP 算法，或者严格遵守 LGPL 的动态链接规则。*

### 4.2 硬件与开发环境投入策略

- **开发机：** 一台 Mac Mini (M1/M2) 用于编译 iOS 版本（约 4000 元）。
- **测试机（关键）：** 需要覆盖低端 Android（如红米/Realme）、中端 Android（Pixel/Samsung）、以及旧款 iPhone。**Android 的音频延迟在不同机型上差异巨大，这是项目成败的关键风险点** 3。
- **云服务：** 初期使用 Firebase 或阿里云 OSS 存储 MIDI 和 SoundFont 文件，按量付费，避免购买服务器。

### 4.3 为什么不选 Unity 或 JUCE？

- **Unity:** 虽然适合做游戏，但处理复杂的乐谱排版（MusicXML 渲染）非常痛苦，且包体过大。
- **JUCE:** 行业标准音频框架，但其商业授权费用（Pro 版）对于 10w 预算的团队是一笔负担，且其 UI 开发效率不如 Flutter 20。Flutter + C++ FFI 是目前最具性价比的“轻量级”替代方案。

------

## 5. 如何提升 MIDI 音质与古典乐版权问题

用户追求“高拟真音质”，这意味着不能使用系统自带的 MIDI 合成器。必须构建自己的采样回放引擎。

### 5.1 提升 MIDI 音质的策略

#### 5.1.1 高质量 SoundFont (音色库) 选型与优化

通用的 General MIDI (GM) 音色库（通常 8MB-30MB）听起来像廉价电子琴。要实现“交响乐感”，需要针对管弦乐进行优化的音色库。

- **音源选择：**
  - **Virtual Playing Orchestra (VPO):** 21 这是一个基于 SFZ 格式的免费管弦乐库，汇集了 Sonatina, VSCO 2 等多个开源采样的精华。它提供多种演奏法（断奏、连奏、颤音）。
  - **VSCO 2 Community Edition:** 23 提供极其干净、真实的乐器采样，CC0 许可（完全免费商用）。
- **移动端优化：**
  - VPO 完整版可能超过 1GB，不适合移动端分发。团队需要使用工具（如 **Polyphone**）将其精简。
  - **策略：** 仅提取协奏曲常用的乐器（独奏小提琴、大提琴、钢琴、长笛、双簧管、单簧管、巴松、小号、圆号、定音鼓、弦乐组）。
  - **压缩：** 将采样率降至 44.1kHz甚至 32kHz，使用 Vorbis 压缩采样数据（SF3 格式），争取将核心库控制在 200MB 以内。

#### 5.1.2 实时“人性化”算法 (Humanization)

真实的乐队不会像机器人一样精准演奏。需要在 C++ 引擎中加入实时处理层 25：

- **微时值随机化 (Micro-timing):** 在 MIDI 触发时间上增加高斯分布的微小随机延迟（±5~15ms），模拟人类演奏的“呼吸感”。
- **动态耦合 (Dynamic Coupling):** ***这是提升体验的杀手锏。\*** 实时分析用户输入的音量（RMS 振幅），将其映射到伴奏 MIDI 的 CC11 (Expression) 或 CC7 (Volume)。当用户拉得更响时，伴奏乐队自动增强音量，产生“互动感”。
- **卷积混响 (Convolution Reverb):** 使用轻量级的卷积混响（加载真实音乐厅的脉冲响应 IR 文件），而非算法混响。这能瞬间让干瘪的 MIDI 采样听起来像是在维也纳金色大厅演奏。

### 5.2 古典乐版权问题解析

版权是音乐软件的雷区。对于古典音乐，需要区分**作曲版权**、**版本版权**和**录音版权** 。

- **作曲版权 (Composition):** 巴赫、莫扎特、贝多芬等去世超过 70 年的作曲家，其作品本身已进入**公有领域 (Public Domain)**，可以免费使用。
- **版本版权 (Editions):** **现代出版社**（如 Henle, Bärenreiter）出版的乐谱，其排版和编辑标记是有版权的。**绝对不能**直接扫描或使用现代乐谱的 PDF。
  - *解决方案：* 使用 **IMSLP** 上标注为 Public Domain 的旧版乐谱（如 1900 年前的 Breitkopf & Härtel 版本）。
- **MIDI 文件版权 (The Derivative Trap):**  即使曲子是公有领域的，别人制作的 MIDI 文件属于“衍生作品”，受版权保护。你不能随意从网上下载一个 MIDI 放入软件商用。
  - *风险：* Kunstderfuge  和 Classical Archives  上的大多数 MIDI 文件严禁商用。
  - *安全来源：* **Mutopia Project**  提供的 MIDI 大多是 Creative Commons 许可，可商用（需署名）。
  - *最佳策略：* **自制内容**。使用 MuseScore 将公有领域的 PDF 乐谱“扒”成 MIDI。这样你们拥有该 MIDI 的 100% 版权，且可以在制作时专门为软件优化（如预设好表情曲线 CC）。

------

## 6. 现成AI解决方案的考察

在 10w 预算下，自研大规模 AI 模型是不现实的。应考察如何集成现有的轻量级 AI。

### 6.1 离线 AI：生成更具表现力的 MIDI

**VirtuosoNet** 33 是一个能够将由乐谱生成的“死板”MIDI 转化为具有人类演奏表情（速度变化、力度变化）的 AI 模型。

- **应用场景：** 在内容生产阶段（Offline）。不要让用户听平直的 MIDI，而是先用 VirtuosoNet 处理一遍你们的 MIDI 库，预先写入自然的 Rubato 和力度曲线。这不需要在手机上运行 AI，不消耗用户算力，但能极大提升听感。

### 6.2 实时 AI：乐谱跟随的增强

虽然我们主要推荐 OLTW 算法，但可以考察 **Neutone SDK** 35 或 **TensorFlow Lite** 用于移动端。

- **场景：** 专门训练一个轻量级 CNN 模型用于“翻页检测”或“手势识别”（如果利用摄像头）。
- **建议：** 鉴于预算，初期不要投入 AI 训练。传统的 DSP 算法（OLTW）在乐谱跟随任务上比端到端 AI 更可控、计算开销更低。

### 6.3 生成式 AI (Generative AI)

如 **Google Magenta** 36。

- **场景：** 当用户停止演奏时，与其让伴奏突然静止，不如让 AI 生成一段过渡性的“Vamp”（即兴填充），直到用户重新开始。
- **结论：** 这是一个“锦上添花”的功能，但在 MVP 阶段过于复杂，且可能引入不可控的音乐元素，建议后续迭代考虑。

------

## 7. 综合建议与实施路线图

基于上述分析，为您的团队制定以下实施路线图：

### 第一阶段：原型验证（第1-2个月）

- **目标：** 跑通“音频输入 -> C++ 引擎 -> MIDI 同步播放”的最小闭环。
- **行动：**
  1. 搭建 Flutter + FFI + C++ 开发环境。
  2. 在 C++ 层集成 Oboe (音频IO) 和 FluidSynth (合成)。
  3. 移植 Matchmaker 的 OLTW 算法，实现简单的单旋律跟随。
  4. 测试 Android 低端机的延迟，确认是否在可接受范围（<20ms）。

### 第二阶段：内容与 UI 构建（第3-4个月）

- **目标：** 完成乐谱渲染与核心曲库制作。
- **行动：**
  1. 集成 Lomse 或 VexFlow 渲染 MusicXML。
  2. **内容生产：** 选取 5 首最热门的协奏曲（如门德尔松 e 小调小提琴协奏曲第一乐章），人工制作高质量 MIDI，包含精细的 CC11 表情控制。
  3. **音色库定制：** 使用 Polyphone 从 VPO/VSCO2 中提取并压缩出一个 150MB 左右的专用 SoundFont。

### 第三阶段：打磨与发布（第5-6个月）

- **目标：** 解决“像机器”的问题。
- **行动：**
  1. 加入“动态耦合”算法，让伴奏音量随用户音量起伏。
  2. 加入卷积混响。
  3. 进行小范围内测（找音乐学院学生），收集关于“跟随灵敏度”的反馈进行参数调优。

### 总结



这是一个典型的**“技术密集型 + 内容驱动型”**项目。10万元的资金非常紧张，必须全部用在刀刃上：**不要花钱做营销，不要花钱买昂贵的服务器，钱要花在购买高质量的 SoundFont 商业授权（如果免费的不够好）和聘请兼职制作高质量 MIDI 数据上。** 技术上，Flutter + C++ + FluidSynth + OLTW 是目前最稳健、成本最低的黄金组合。

------

